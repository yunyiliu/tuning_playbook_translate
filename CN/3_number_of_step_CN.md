确定每个训练运行的步数

- 有两种类型的工作负载：计算密集型和非计算密集型。
- 当训练是计算密集型时，训练受到我们愿意等待的时间限制，而不是训练数据量或其他因素的限制。
	- 在这种情况下，如果我们能够以某种方式更长或更有效地进行训练，我们应该能够看到更低的训练损失和通过适当的调整，改善验证损失。
	- 换句话说，加快训练就相当于改善训练，而“最佳”训练时间始终是“尽可能长”。
	- 尽管如此，仅因为工作负载受计算限制并不意味着延长/加快训练是改善结果的唯一方法。
- 当训练不是计算密集型时，我们可以负担得起训练的时间，但在某些时候，训练时间过长并不能帮助太多（甚至会导致问题性过拟合）。
	- 在这种情况下，我们应该期望能够将训练损失降到非常低的水平，即使延长训练时间可能会略微降低训练损失，但不会显著降低验证损失。
	- 特别是当训练不受计算限制时，更充裕的训练时间预算可以使调整更容易，特别是在调整学习率衰减计划时，因为它们与训练预算有着特别强的相互作用。
		- 换句话说，非常吝啬的训练时间预算可能需要完美调整的学习率衰减计划才能实现良好的错误率。
- 无论给定的工作负载是计算限制还是不受限制，增加梯度的方差（跨批次）的方法通常会导致训练进度较慢，因此可能需要增加训练步骤才能达到特定的验证损失。高梯度方差可能由以下原因引起：
	- 使用较小的批量大小
	- 添加数据增强
	- 添加某些类型的正则化（例如丢弃）


当训练不受计算限制时，如何决定训练时间：

- 我们的主要目标是确保训练足够长，使模型达到最佳结果，同时避免在训练步骤数量上过于浪费。
- 如果有疑虑，应该选择更长的训练时间。假设回顾（最优）检查点选择被正确使用并且检查点足够频繁，训练时间越长，性能不应该下降。
- 在研究中永远不要调整 max_train_steps 数值。选择一个数值并在所有试验中使用它。从这些试验中，可以绘制回顾检查点选择找到的训练步骤，以便优化 max_train_steps 的选择。
	- 例如，如果最佳步骤始终在训练的前10%中，那么最大步数太高了。
	- 或者，如果最佳步骤一直在训练的最后25%中，我们可能会受益于更长的训练时间并重新调整衰减进度。
- 当体系结构或数据发生变化时（例如添加数据增强），理想的训练步数可能会改变。
	- 下面我们将描述如何根据使用恒定学习率“完美拟合”训练集所需的步骤数选择 max_train_steps 的初始候选值。
		- 请注意，我们并没有以精确或数学上定义良好的方式使用“完美拟合训练集”这个短语。它仅仅作为一个非正式的描述符，用于指示训练损失非常低的情况。
			- 例如，在使用对数损失进行训练时，如果没有正则化项，我们可能会看到训练损失保持缓慢改善，直到网络权重无限增长且模型对训练集的预测变得越来越自信，此时我们可能会认为模型在训练集上“完美拟合”。
		- 找到的 max_train_steps 的起始值可能需要增加，如果训练过程中的梯度噪声增加。
			- 例如，如果在模型中引入了数据增强或dropout等正则化器。
		- 如果训练过程有所改善，可能可以降低 max_train_steps。
			- 例如，通过更好地调整优化器或学习率进度。
